{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Давайте создадим AI чат бота..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идея"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Давайте обсудим, для чего это нужно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Сильный AI может стать бесполезным, если не сможет общаться с людьми\n",
    "2. Даже если не мечтать про сильный AI, умение \"понимать\" и осмысленно отвечать на человеческом языке может сильно помочь в автоматизации службы поддержки компании и др.\n",
    "3. Изучение новой технологии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Цель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Создание чат бота, поддерживающего беседу\n",
    "* Изучение технологий, необходимых для этого"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Let's do this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Загрузим и подготовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                            !wget https://www.dropbox.com/s/tfeozvw4hfnmufu/subtitles.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/cpcfs5y6z4qqhc0/Networks_weights.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/u9873fsq6r4he28/token_id.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import codecs\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "PAD_ix = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"dataset.txt\") as fp:\n",
    "    data = fp.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['насколько\\\\@/ \\\\@/может\\\\@/ \\\\@/быть\\\\@/ \\\\@/силь\\\\@/ным\\\\@/ \\\\@/само\\\\@/вну\\\\@/ш\\\\@/ение?',\n",
       " 'сила\\\\@/ \\\\@/вну\\\\@/шения\\\\@/ \\\\@/может\\\\@/ \\\\@/быть\\\\@/ \\\\@/очень\\\\@/ \\\\@/большо\\\\@/й.',\n",
       " 'часто\\\\@/ \\\\@/ли\\\\@/ \\\\@/боле\\\\@/ют\\\\@/ \\\\@/поляр\\\\@/ники\\\\@/ \\\\@/на\\\\@/ \\\\@/рабо\\\\@/те?',\n",
       " 'вообще\\\\@/ \\\\@/не\\\\@/ \\\\@/боле\\\\@/ют.',\n",
       " 'где-нибудь\\\\@/ \\\\@/кроме\\\\@/ \\\\@/россии\\\\@/ \\\\@/еще\\\\@/ \\\\@/боятся\\\\@/ \\\\@/сквоз\\\\@/ня\\\\@/ка?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(text):\n",
    "    return re.split(r\"\\\\@/\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235633/235633 [00:04<00:00, 52027.90it/s]\n"
     ]
    }
   ],
   "source": [
    "phrase_list = []\n",
    "for i in tqdm(range(0, len(data), 2)):\n",
    "    try:\n",
    "        phrase_list.append([split(data[i]), split(data[i+1])])\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join(l):\n",
    "    return \" \".join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235632/235632 [00:01<00:00, 125276.03it/s]\n"
     ]
    }
   ],
   "source": [
    "symb = \"\"\n",
    "for s in tqdm(phrase_list):\n",
    "    symb += \" \".join(list(map(join, s))) + \"  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы генирируем ответы посимвольно, определимся, какие символы у нас встречаются "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = set(symb.split() + [\" \"])\n",
    "\n",
    "tokens = list(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обозначения начала и конца будем использовать START и END. Превратим каждое наше предложение в список символов, которые оно содержит, добавим обозначение начала и конца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = [\"START\"] + tokens + [\"END\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15892"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrase_list = list(map(lambda s: list(map(lambda x: [\"START\"] + x + [\"END\"], s)), phrase_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235632"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrase_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь token - id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {tok: i for i, tok in enumerate(tokens)}\n",
    "\n",
    "id_to_token = {token_to_id[tok]: tok for tok in token_to_id.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем превращать все наши предложения в матрицу, имеющую форму (кол-во предложений, мак-ое кол-во символов в предложении), если остаются пустые ячейки заполним их -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_matrix(sequences,token_to_i, max_len=None,PAX_ix=PAD_ix, extra_max_len=None):\n",
    "    max_len = max_len or max(map(len,sequences))\n",
    "    max_len = np.min([max_len, extra_max_len]) if extra_max_len else max_len\n",
    "    \n",
    "    matrix = np.zeros((len(sequences),max_len),dtype='int32') -1\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = list(filter(None.__ne__, map(token_to_i.get,seq)))[:max_len]\n",
    "        matrix[i,:len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем в токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0  3528 11760 13068 11760  3197 11760 14661 15479 11760 14579 12208\n",
      "   7599  3682 15891]\n",
      " [    0  2875 11760 12208 15730 11760 13068 11760  3197 11760  6054 11760\n",
      "  14546  6578 15891]]\n"
     ]
    }
   ],
   "source": [
    "print(as_matrix(phrase_list[0], token_to_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"tokens_id.json\", \"w\") as fp:\n",
    "    json.dump({\"token_to_id\":token_to_id, \"id_to_token\": id_to_token, \"tokens\": tokens}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"tokens_id.json\") as f:\n",
    "    tokens_id = json.load(f)\n",
    "token_to_id = tokens_id[u'token_to_id']\n",
    "id_to_token = tokens_id[\"id_to_token\"]\n",
    "tokens = tokens_id[\"tokens\"]\n",
    "tokens = tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим сеть, которая будет получать на вход вопрос и генерировать посимвольно ответ на него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=gpu3,floatX=float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 3: GeForce GTX 1080 (CNMeM is enabled with initial size: 22.0% of memory, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=device=gpu3,floatX=float32\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.objectives import categorical_crossentropy\n",
    "from lasagne.updates import adam\n",
    "from hierarchical_softmax_layer import HierarchicalSoftmaxDenseLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequence','int32')\n",
    "target_phonemes = T.matrix('target phonemes','int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##ENCODER\n",
    "l_in = lasagne.layers.InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "l_mask = lasagne.layers.InputLayer(shape=(None, None),input_var=T.neq(input_sequence,-1))\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, len(tokens), 256)\n",
    "l_rnn = lasagne.layers.LSTMLayer(l_emb,256,mask_input=l_mask)\n",
    "l_rnn = lasagne.layers.LSTMLayer(l_rnn,256,only_return_final=True,mask_input=l_mask)\n",
    "\n",
    "##DECODER\n",
    "transc_in = lasagne.layers.InputLayer(shape=(None, None),input_var=target_phonemes)\n",
    "transc_mask = lasagne.layers.InputLayer(shape=(None, None),input_var=T.neq(target_phonemes,-1))\n",
    "transc_emb = lasagne.layers.EmbeddingLayer(transc_in, len(tokens), 50)\n",
    "transc_rnn = lasagne.layers.LSTMLayer(transc_emb,256,hid_init=l_rnn,mask_input=transc_mask)\n",
    "transc_rnn = lasagne.layers.LSTMLayer(transc_rnn,256,hid_init=l_rnn,mask_input=transc_mask)\n",
    "\n",
    "\n",
    "#flatten batch and time to be compatible with feedforward layers (will un-flatten later)\n",
    "transc_rnn_flat = lasagne.layers.reshape(transc_rnn, (-1,transc_rnn.output_shape[-1]))\n",
    "\n",
    "l_out = lasagne.layers.DenseLayer(transc_rnn_flat,len(tokens),nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, W, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, W, b]\n"
     ]
    }
   ],
   "source": [
    "weights = lasagne.layers.get_all_params(l_out, trainable=True)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_output = lasagne.layers.get_output(l_out)\n",
    "network_output = network_output.reshape([target_phonemes.shape[0], target_phonemes.shape[1], -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crossentropy(answ):\n",
    "    return -1*T.log(answ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_flat = network_output[:,:-1,:].reshape([-1, len(tokens)])\n",
    "targets = target_phonemes[:,1:].ravel()\n",
    "\n",
    "mask = T.nonzero(T.neq(targets, -1))\n",
    "\n",
    "loss = categorical_crossentropy(predictions_flat[mask], targets[mask]).mean()\n",
    "updates = adam(loss, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Компилируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#training\n",
    "train = theano.function([input_sequence, target_phonemes], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#computing loss without training\n",
    "compute_cost = theano.function([input_sequence, target_phonemes], loss, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создадим генератор ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile the function that computes probabilities for next token given previous text.\n",
    "\n",
    "#reshape back into original shape\n",
    "network_output = network_output.reshape((target_phonemes.shape[0],target_phonemes.shape[1],len(tokens)))\n",
    "#predictions for next tokens (after sequence end)\n",
    "last_word_probas = network_output[:,-1]\n",
    "probs = theano.function([input_sequence,target_phonemes],last_word_probas,allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from apply_bpe import BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"codes.txt\") as fp:\n",
    "    bpe = BPE(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мы все учились по@@ не@@ мно@@ гу'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.segment(\"мы все учились понемногу\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_bpe(text):\n",
    "    text = bpe.segment(text)\n",
    "    text = re.sub(r\"@@ \", \"\\@/\", text)\n",
    "    return re.sub(r\" \", \"\\@/ \\@/\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_answer(question,answer_prefix = (\"START\",),t=1,sample=True, max_len=40):\n",
    "    \n",
    "    answer = list(answer_prefix)\n",
    "    question = question.lower()\n",
    "    question = [\"START\"] + re.split(r\"\\\\@/\", apply_bpe(question)) + [\"END\"]\n",
    "    for _ in range(max_len):\n",
    "#         print(as_matrix([question],token_to_id))\n",
    "        if len(answer) < 2:\n",
    "            answ_matrix = as_matrix([answer],token_to_id, max_len=2)\n",
    "        else:\n",
    "            answ_matrix = as_matrix([answer],token_to_id)\n",
    "#         print(answ_matrix)\n",
    "        next_let_probs = probs(as_matrix([question],token_to_id), answ_matrix).ravel()\n",
    "        next_let_probs = next_let_probs**t / np.sum(next_let_probs**t)\n",
    "\n",
    "        if sample:\n",
    "            next_letter = np.random.choice(tokens,p=next_let_probs) \n",
    "        else:\n",
    "            next_letter = tokens[np.argmax(next_let_probs)]\n",
    "        \n",
    "        answer.append(next_letter)\n",
    "\n",
    "        if next_letter==\"END\":\n",
    "            break\n",
    "    return \"\".join(answer[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "себе.ленныйнынешнихджсрокалгоритсахараинстафилософсвоимфетиссыоперсекунаучно-балти①помидорами.ге.инфекособуспокопосмотретьрасскажпроизвелирайоненаличиичувствусвободуピтвоиэзоспособпищеблодневпеснива,\n"
     ]
    }
   ],
   "source": [
    "print(generate_answer(\"насколько может быть сильным самовнушение?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузим предобученые веса, если есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with np.load(\"Networks_weights.npz\", encoding=\"bytes\") as weights_file:\n",
    "    lasagne.layers.set_all_param_values(l_out, weights_file[\"arr_0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тренируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parametrs = {\"token_to_i\": token_to_id,\n",
    "             \"extra_max_len\": 300}\n",
    "def iterate_minibatches(source, batchsize, shuffle=True):\n",
    "    source = np.array(source)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(source)-1)\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(source) -1 - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = np.array(slice(start_idx, start_idx + batchsize))\n",
    "#         print(len(source[excerpt]))\n",
    "#         yield source[excerpt]\n",
    "        yield as_matrix(source[excerpt][:, 0], **parametrs), as_matrix(source[excerpt][:, 1], **parametrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "telegram_token = config.telegram_token\n",
    "telegram_chat_id = config.telegram_chat_id# id чата, в который будут отсылаться результаты в процессе обучения, так как она учится долго\n",
    "dropbox_token = config.dropbox_token# Свежие веса загружаются на в облако, чтобы не потерять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from telebot import TeleBot\n",
    "bot = TeleBot(telegram_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:3: DeprecationWarning: You are using a deprecated client. Please use the new v2 client located at dropbox.Dropbox.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "import dropbox\n",
    "\n",
    "client = dropbox.client.DropboxClient(dropbox_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_message = \"Epoch {epoch}:\\nTime {time_:.2f} hours\\nAverage loss: {avg_los:.5f}\\nExample(насколько может быть сильным самовнушение?):\\n\\t{sample}\"\n",
    "train_error_messages = \"Error on epoch when we train model: {}\\n\\t{}\\nBatch:\\n{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time, sleep\n",
    "num_epoch = 100\n",
    "batch_per_epoch = 9000\n",
    "batch_size = 25\n",
    "bot.send_message(145718567, \"Learning is begin!\")\n",
    "error = False\n",
    "for epoch in range(num_epoch):\n",
    "#     try:\n",
    "#     time.sleep(0.1)\n",
    "    st = time()\n",
    "    avg_cost = 0\n",
    "    for batch_num, batch in enumerate(iterate_minibatches(phrase_list, batch_size)):\n",
    "#         print(batch[0].shape, batch[1].shape)\n",
    "#         print(batch[0].dtype, batch[1].dtype)\n",
    "        try:\n",
    "            avg_cost += train(batch[0], batch[1])\n",
    "        except Exception as er:\n",
    "            bot.send_message(telegram_chat_id, train_error_messages.format(epoch+1, er, (batch[0].shape, batch[1].shape)))\n",
    "            error = True\n",
    "            break\n",
    "\n",
    "        if batch_num+1 == batch_per_epoch:\n",
    "            break\n",
    "\n",
    "    if error:\n",
    "        break\n",
    "\n",
    "    weights_file = \"Networks_weights1.npz\"\n",
    "    np.savez(weights_file, layers.get_all_param_values(l_out))\n",
    "#         try:\n",
    "#             with open(weights_file, 'rb') as weights_file_dr:\n",
    "#                 response = client.put_file('/' + weights_file, weights_file_dr)\n",
    "\n",
    "#         except Exception as er:\n",
    "#             bot.send_message(telegram_chat_id, \"Error of download to Dropbox: {}\".format(e))\n",
    "\n",
    "    bot.send_message(145718567, train_message.format(time_=(time()-st)/60,\n",
    "                                                     epoch=epoch+1,\n",
    "                                                     avg_los=avg_cost/batch_per_epoch,\n",
    "                                                    sample=generate_answer(\"насколько может быть сильным самовнушение?\")))\n",
    "\n",
    "#     except Exception as er:\n",
    "#         bot.send_message(telegram_chat_id, \"Error on epoch: {}\\n\\t{}\".format(epoch+1, er))\n",
    "#         break\n",
    "bot.send_message(telegram_chat_id, \"Learning is end!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_answer(\"насколько может быть сильным самовнушение?\", sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
